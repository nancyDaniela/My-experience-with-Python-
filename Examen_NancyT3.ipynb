{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEVs7iWug1Da"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P4z5gKDMhDe6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un grupo de investigación en Biología Marina está realizando mediciones en un molusco en el cual están interesados, estos datos los están almacenando en una base de datos desde hace ya un tiempo atrás (abalone.csv).\n",
        "\n",
        "La información que guardan es la relacionada a:  Sex, Length, Diameter, Height, Whole_weight, Shucked_weight, Viscera_weight y Rings.\n",
        "\n",
        "Pero últimamente han recolectado datos de los cuales no han podido determinar el Sex del molusco.\n",
        "\n",
        "Decidieron hacer un proceso de clasificación con los datos que si conocen para calcular el valor de Sex  faltante.\n",
        "\n",
        "En el proceso de clasificación es probable que tengan que validar datos no capturados e imputarlos con los valores promedio o el valor más frecuente de cada columna y mostrar gráficamente como están los datos antes y después de la imputación, también decidieron hacer un histograma por cada columna.\n",
        "\n",
        "También puede contener caracteres no validos en columnas numéricas.\n",
        "\n",
        "Una vez teniendo listos los datos para la clasificación, decidieron probrar con varios métodos.\n",
        "\n",
        "Encontrado el mejor modelo de clasificación de alguna de estas técnicas, tomarán ese mejor modelo para hacer la clasificación del valor Sex  en el archivo (abalone_missing.csv) que puede tener valores faltantes las columnas o en su caso puede contener caracteres no validos a en columnas numéricas. (Los valores faltantes de Sex, no deben de ser removidos)."
      ],
      "metadata": {
        "id": "kIexG_3NhDnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresion - abalone.csv"
      ],
      "metadata": {
        "id": "XBuWLoenzkj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet, LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
        "\n",
        "\n",
        "archivo=\"/content/drive/MyDrive/datasets/abalone.csv\"\n",
        "df=pd.read_csv(archivo,sep=\",\",header=0) \n",
        "\n",
        "le=LabelEncoder()\n",
        "df[\"sex_le\"]=le.fit_transform(df[\"Sex\"])\n",
        "\n",
        "# ANTES DE LA IMPUTACION Y LIMPIEZA\n",
        "#ax=msno.bar(df)\n",
        "#ax.get_figure().show()\n",
        "\n",
        "#imputacion\n",
        "si=SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
        "df.sex_le=si.fit_transform(df.sex_le.values.reshape(-1,1)) \n",
        "\n",
        "\n",
        "#LIMPIEZA \n",
        "df=df.replace({\"Diameter\":{\".\":0}}) \n",
        "df[\"Diameter\"] = df[\"Diameter\"].astype(\"float64\")\n",
        "\n",
        "df=df.replace({\"Shucked_weight\":{\"a\":0, \"s\":0}}) \n",
        "df[\"Shucked_weight\"] = df[\"Shucked_weight\"].astype(\"float64\")\n",
        "\n",
        "df=df.replace({\"Viscera_weight\":{\"a\":0, \"s\":0, \"e\":0, \"r\":0,\"w\":0,\"f\":0,\"g\":0,\"h\":0,\"u\":0,\"df\":0}})\n",
        "df[\"Viscera_weight\"] = df[\"Viscera_weight\"].astype(\"float64\")\n",
        "\n",
        "df=df.replace({\"Shell_weight\":{\"a\":0, \"s\":0}}) \n",
        "df[\"Shell_weight\"] = df[\"Shell_weight\"].astype(\"float64\")\n",
        "\n",
        "df=df.fillna(0)\n",
        "\n",
        "#DESPUES DE LA IMPUTACION Y LIMPIO\n",
        "#ax=msno.bar(df)\n",
        "#ax.get_figure().show()\n",
        "\n",
        "\n",
        "#ESCOGIENDO EL MEJOR MODELO ENTRENADO\n",
        "features=[\"Length\",\"Diameter\", \"Height\", \"Whole_weight\", \"Shucked_weight\", \"Viscera_weight\",\"Rings\"]\n",
        "\n",
        "train,test, train_label, test_label = train_test_split(df[features],df[\"sex_le\"],random_state=0, train_size=0.30)\n",
        "\n",
        "lr=LogisticRegression()\n",
        "modelo= lr.fit(train,train_label)\n",
        "prediccion= modelo.predict(test)\n",
        "\n",
        "prediccion_list=prediccion.tolist() \n",
        "test_label_list=test_label.tolist()\n",
        "\n",
        "score= modelo.score(test,test_label)\n",
        "mae= mean_absolute_error(prediccion,test_label) \n",
        "mse= mean_squared_error(prediccion,test_label) \n",
        "\n",
        "#score= modelo.score(test,test_label) \n",
        "#acs= accuracy_score(prediccion,test_label)  \n",
        "#cm= confusion_matrix(prediccion,test_label) \n",
        "#cr= classification_report(prediccion,test_label) \n",
        "\n",
        "#print(\"score= \", score, \"\\naccuracy_score=\", acs,\"\\nconfusion_matrix=\", cm,\"\\nclassification_report=\",cr)\n",
        "print(\"score= \", score, \"\\nmedia error absoluto=\", mae,\"\\nmedia error cuadrado=\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCqCmEDohq4X",
        "outputId": "28cd06ce-1ed2-45b3-d745-6b4e5b31dedf"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score=  0.5557455540355677 \n",
            "media error absoluto= 0.6939124487004104 \n",
            "media error cuadrado= 1.1932284541723666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados obtenidos:\n",
        "\n",
        "## Mejor modelo de regresion: Logistic Regression\n",
        "\n",
        "*   LinearRegression: \n",
        "\n",
        "> score=  0.0068677723838376226 \n",
        "\n",
        "*   Ridge:\n",
        "\n",
        "> score=  0.006645628898964473\n",
        "\n",
        "\n",
        "*   Lasso:\n",
        "\n",
        "> score=  -8.627955343820659e-05\n",
        "\n",
        "\n",
        "*   ElasticNet:\n",
        "\n",
        "> score=  -8.627955343820659e-05\n",
        "\n",
        "\n",
        "*   LogisticRegression:\n",
        "\n",
        "> score=  0.5557455540355677\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jskZE-EwtmZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificacion - abalone.csv"
      ],
      "metadata": {
        "id": "XzMleSeqzpMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n",
        "\n",
        "\n",
        "archivo=\"/content/drive/MyDrive/datasets/abalone.csv\"\n",
        "df=pd.read_csv(archivo,sep=\",\",header=0) \n",
        "\n",
        "le=LabelEncoder()\n",
        "df[\"sex_le\"]=le.fit_transform(df[\"Sex\"])\n",
        "\n",
        "# ANTES DE LA IMPUTACION Y LIMPIEZA\n",
        "#ax=msno.bar(df)\n",
        "#ax.get_figure().show()\n",
        "\n",
        "#imputacion\n",
        "si=SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
        "df.sex_le=si.fit_transform(df.sex_le.values.reshape(-1,1)) \n",
        "\n",
        "\n",
        "#LIMPIEZA \n",
        "df=df.replace({\"Diameter\":{\".\":0}}) \n",
        "df[\"Diameter\"] = df[\"Diameter\"].astype(\"float64\")\n",
        "\n",
        "df=df.replace({\"Shucked_weight\":{\"a\":0, \"s\":0}}) \n",
        "df[\"Shucked_weight\"] = df[\"Shucked_weight\"].astype(\"float64\")\n",
        "\n",
        "df=df.replace({\"Viscera_weight\":{\"a\":0, \"s\":0, \"e\":0, \"r\":0,\"w\":0,\"f\":0,\"g\":0,\"h\":0,\"u\":0,\"df\":0}})\n",
        "df[\"Viscera_weight\"] = df[\"Viscera_weight\"].astype(\"float64\")\n",
        "\n",
        "df=df.replace({\"Shell_weight\":{\"a\":0, \"s\":0}}) \n",
        "df[\"Shell_weight\"] = df[\"Shell_weight\"].astype(\"float64\")\n",
        "\n",
        "df=df.fillna(0)\n",
        "\n",
        "#DESPUES DE LA IMPUTACION Y LIMPIO\n",
        "#ax=msno.bar(df)\n",
        "#ax.get_figure().show()\n",
        "\n",
        "\n",
        "#ESCOGIENDO EL MEJOR MODELO ENTRENADO\n",
        "features=[\"Length\",\"Diameter\", \"Height\", \"Whole_weight\", \"Shucked_weight\", \"Viscera_weight\",\"Rings\"]\n",
        "\n",
        "train,test, train_label, test_label = train_test_split(df[features],df[\"sex_le\"],random_state=0, train_size=0.30)\n",
        "\n",
        "lr=GradientBoostingClassifier()\n",
        "modelo= lr.fit(train,train_label)\n",
        "prediccion= modelo.predict(test)\n",
        "\n",
        "prediccion_list=prediccion.tolist() \n",
        "test_label_list=test_label.tolist()\n",
        "\n",
        "\n",
        "score= modelo.score(test,test_label) \n",
        "acs= accuracy_score(prediccion,test_label)  \n",
        "cm= confusion_matrix(prediccion,test_label) \n",
        "cr= classification_report(prediccion,test_label) \n",
        "\n",
        "print(\"score= \", score, \"\\naccuracy_score=\", acs,\"\\nconfusion_matrix=\", cm,\"\\nclassification_report=\",cr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4wCGafcxqZB",
        "outputId": "835b96be-5fdf-437a-b834-f503a36be682"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score=  0.5434336525307798 \n",
            "accuracy_score= 0.5434336525307798 \n",
            "confusion_matrix= [[312  70 303]\n",
            " [117 700 188]\n",
            " [491 166 577]] \n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.34      0.46      0.39       685\n",
            "         1.0       0.75      0.70      0.72      1005\n",
            "         2.0       0.54      0.47      0.50      1234\n",
            "\n",
            "    accuracy                           0.54      2924\n",
            "   macro avg       0.54      0.54      0.54      2924\n",
            "weighted avg       0.56      0.54      0.55      2924\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Mejor modelo de clasificacion: GradientBoostingClassifier\n",
        "\n",
        "*   DecisionTreeClassifier:\n",
        "> score=   0.4904240766073871 \n",
        "\n",
        "\n",
        "*   RandomForestClassifier\n",
        "> score=  0.5294117647058824 \n",
        "\n",
        "\n",
        "*   GradientBoostingClassifier\n",
        "> score=  0.5434336525307798\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qf9XFnB_0jnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificacion - abalone_missing.csv"
      ],
      "metadata": {
        "id": "8VgY-80z18w7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n",
        "\n",
        "archivo=\"/content/drive/MyDrive/datasets/abalone_missing.csv\"\n",
        "df=pd.read_csv(archivo,sep=\",\",header=0) \n",
        "\n",
        "\n",
        "\n",
        "df=df.fillna(0) #Rellenar datos nulos \n",
        "\n",
        "#LIMPIEZA \n",
        "df=df.replace({\"Diameter\":{\"g\":0}}) \n",
        "df[\"Diameter\"] = df[\"Diameter\"].astype(\"float64\")\n",
        "\n",
        "df=df.replace({\"Length\":{\"u\":0}}) \n",
        "df[\"Length\"] = df[\"Length\"].astype(\"float64\")\n",
        "\n",
        "df=df.replace({\"Height\":{\"s\":0, \"hre\":0, \"r\":0, \"u\":0,\"fg\":0}}) \n",
        "df[\"Height\"] = df[\"Height\"].astype(\"float64\")\n",
        "\n",
        "df=df.replace({\"Whole_weight\":{\"g\":0, \"s\":0, \"jk\":0, \"u\":0,\"fg\":0}}) \n",
        "df[\"Whole_weight\"] = df[\"Whole_weight\"].astype(\"float64\")\n",
        "\n",
        "df=df.replace({\"Viscera_weight\":{\"asd\":0, \"d\":0, \"s\":0, \"f\":0,\"i\":0}}) \n",
        "df[\"Viscera_weight\"] = df[\"Viscera_weight\"].astype(\"float64\")\n",
        "\n",
        "\n",
        "\n",
        "#ESCOGIENDO EL MEJOR MODELO ENTRENADO\n",
        "features=[\"Length\",\"Diameter\", \"Height\", \"Whole_weight\", \"Shucked_weight\", \"Viscera_weight\",\"Rings\"]\n",
        "\n",
        "train,test, train_label, test_label = train_test_split(df[features],df[\"Sex\"],random_state=0, train_size=0.30)\n",
        "\n",
        "lr=GradientBoostingClassifier()\n",
        "modelo= lr.fit(train,train_label)\n",
        "prediccion= modelo.predict(test)\n",
        "\n",
        "prediccion_list=prediccion.tolist() \n",
        "test_label_list=test_label.tolist()\n",
        "\n",
        "\n",
        "score= modelo.score(test,test_label) \n",
        "acs= accuracy_score(prediccion,test_label)  \n",
        "cm= confusion_matrix(prediccion,test_label) \n",
        "cr= classification_report(prediccion,test_label) \n",
        "\n",
        "print(\"score= \", score, \"\\naccuracy_score=\", acs,\"\\nconfusion_matrix=\", cm,\"\\nclassification_report=\",cr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "LIFl4CST145E",
        "outputId": "eea4c855-ed55-43eb-8a1b-3c268bf36c3e"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-29eb77c4c8f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodelo\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprediccion\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_validate_y\u001b[0;34m(self, y, sample_weight)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0mn_trim_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_trim_classes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1273\u001b[0m                 \u001b[0;34m\"y contains %d class after sample_weight \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m                 \u001b[0;34m\"trimmed classes with zero weights, while a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required."
          ]
        }
      ]
    }
  ]
}